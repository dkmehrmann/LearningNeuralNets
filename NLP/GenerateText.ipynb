{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostly taken from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2424839482597916420\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11326380442\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17117148875319190852\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "# use only the first 100k chars\n",
    "text = text.replace(\"\\n\", \" \")[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 51\n",
      "nb sequences: 33320\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33320, 40, 51)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface   supposing that truth is a woma'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how a \"p\" is represented\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29696     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 51)                3315      \n",
      "=================================================================\n",
      "Total params: 33,011\n",
      "Trainable params: 33,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"r? \"by means of a means (faculty)\"--but \"\n",
      "r? \"by means of a means (faculty)\"--but the sourd the sention of the self the for the oreent and and and and and and the serest of the surser the the serpers and and and in in the the surest of the sulpers and and and the preare the suresting and and the inderanter the preestion of the fore and in the serestion and and and the sure the serition and and and and and and and and and the serention and and and and and the sention and and and\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"r? \"by means of a means (faculty)\"--but \"\n",
      "r? \"by means of a means (faculty)\"--but in the rerate the serned of the restionand, suthe and the orition of the strery his of the the caising, and in of all in the rane the surpenters the suruent of the reerion of the praiste and mand the to rieced than whill for the preonenty of sullestly and wallly and not in the meers and and and the suress and dealle the han the carinestion, in of the sementey the suntion is sentioss and surest of \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"r? \"by means of a means (faculty)\"--but \"\n",
      "r? \"by means of a means (faculty)\"--but that juryomy not hessels pcareh mp. ho susiancivito,hs snceeast and and peenclat, for with siflould as wind ast is verionely, peofawan itsely--and lituetiongury and exnuts and onetrvent, the ranes, the riont ouse opleptatry , and sne,  had ariels of shay to sh the gar. an neihestinguriilversyit and m, uichy ptilmenitesterk es as irtined llnes nore the the xlited buinterios and hablionfly ol outros\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"r? \"by means of a means (faculty)\"--but \"\n",
      "r? \"by means of a means (faculty)\"--but \"forph mactestarey\" f onstenss his sblptioddo\"\", of than as mithins souldonay sourvathy geroy akoubpilly ane of the hkestuna!,\"--latomursti infe,-bithat audose! which sieric'userysef und charigsdusps. one suimityl vecrorelth\"ilytt watker ar\" in thay thes dafs. onr w, akinecy. s\"phsurdanin e!pirgion?, forationuancerpitoilfe. pirpertenous , mut obly, pastlad, of thut the eely oonase bisunsth;arouiri\n",
      "81s - loss: 2.2872\n",
      "Epoch 2/60\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"putting in motion \"arms and legs,\" comme\"\n",
      "putting in motion \"arms and legs,\" commenter the sould and and and and and and and and the man its all the alle the enting it the make and and and and the sented the mare the even and it the make in the all the sould and the the enting the an the interser the to as the make and and and the and and and the mare the all the the fire and all the every and all the enting the every in the all the senser the all the must and and and it the se\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"putting in motion \"arms and legs,\" comme\"\n",
      "putting in motion \"arms and legs,\" commes the musery has unders of the tounters and the mist of the effertion of the to this preaser of the sint the in the trought has the fire beoring and gence conentinge with the ulof every which cause the intermont with the rikery the might and its almentale the mage willest and and the will in theurely and in the even in every the strake, and has the thementing becale of the sour the mame it its tha\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"putting in motion \"arms and legs,\" comme\"\n",
      "putting in motion \"arms and legs,\" comments anber \"laritiveritayiingere, the amer\"ly interten befe-falats and gernatoure soule fore inverian ulay evi an unfine reca! conse\"-and aucc; somectinternosso-and beking lift, cote, that thampelfipes dat howe pat volitire every terest to every snagg coualiniciation of tha ourent, pyesterde hose mugay it, it to even and mase gbase. one soutds. the hentule,mite still\" theme lises ade are--impiliita\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"putting in motion \"arms and legs,\" comme\"\n",
      "putting in motion \"arms and legs,\" comme, labed ophtendoshing mb)ould ex-owe soistbve stmimaed, wsun dourithe of cane, \"oneoness, be hove of ulss-supse, at is distreveltios, ar' anri-fine mare, tanem asteqmente ficuchegs naisoly ?fnhiin,  them, the cimmade, (\"ne sepurt terat naturiticitnxthoxuonlytn,untilein time hutheni not phy?oductatos itsomd, thime note. with the utter, trinsti-wealion ceace with on that , at thish imnfeanem tumpre,\n",
      "78s - loss: 1.9313\n",
      "Epoch 3/60\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"against certain other possibilities of w\"\n",
      "against certain other possibilities of which a presing that the self--in in the self-the semution of the self--in the self--in an in or a present the sersity of the serses and the self--it is an in the semulle that the self--in in the secuent of the self--it is what a presentic that in the self--in in the world--in the self--in the self--it is a present in the mast and the sermation of the sent in the serses and the self--in the the sel\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"against certain other possibilities of w\"\n",
      "against certain other possibilities of what it the case the section--it is the siry that mererention of semition in the most and or man what the gerperperientes of the west, who hore in the belief belong the germator only man it in the the sessitions and the free the persistors of one the world of an mo all semution of soulally the self-for the sermation of the falle in what which semution of the as in in the will\" and and ore one and a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"against certain other possibilities of w\"\n",
      "against certain other possibilities of wall in  a to and may wothheresultesre where perperuticill--in are we germm. to the se madened thengenioration i sompent in en ancaresy\" as the  \"worlf--sthesh it not io tone, eruve pand corto dincesit of a maisic or that what all cruite recamed is at has it  modelf to thin for as life go mas underen or \"feen whinh is discreatic therral as i suless even nor serprese in in they for the serprestond a\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"against certain other possibilities of w\"\n",
      "against certain other possibilities of wute the semloc at everyimencate in only, \"stunely neci\"merate prugath wather thas though in the lash-dolas we \"way exinnermhaphysialduilogisuins oyly boukorenik. buirencemoly conce\"tiin with would me then presebrigry andarity soeeff them, cansusest\"ann, rawkee i astivuth,  he anthenetooudhe cilpient, bylohrw! in this ogicel--oneam, has keve pals, philosho-tyesicik, is may in the tresd be what wore\n",
      "77s - loss: 1.8018\n",
      "Epoch 4/60\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"o, a good deal more silent. it happens m\"\n",
      "o, a good deal more silent. it happens mose and the sore and of all the the will the beliefing the beliefing the seely the moral of the such all the such and all the all the sense and more and and who mase and the such all the the sile the some all the some the seely the such all the seely and the seely and the sense and and all the such all the could and the such all the also and and and see to and and the such a soul of the sense and \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"o, a good deal more silent. it happens m\"\n",
      "o, a good deal more silent. it happens mose howeent who the soul consciently and sense and all the for the leas time and things ind all the such is the most and is the the things and every of the will the of also the who that the have men the good his full--the the for the sension of the mad concears of a thing of the suche and the also their migally and of the some and seemation of the such alsot, the alsoring of of mall and all the th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"o, a good deal more silent. it happens m\"\n",
      "o, a good deal more silent. it happens mech of must as it pailo indinatered. this cesintare cuaral alseruved this bisits leowtres itse. and belose the becaud. in the seing the srematiaty of the fwar, geneds are command be sornors ansme as acte--thing at powe as excidainctiainy esuslgruring more a \"peaoss of lightard efach whowill is the beliesic of to are the speaus lefinty and is is atylroubly at this very af eroth we firts immaps thin\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"o, a good deal more silent. it happens m\"\n",
      "o, a good deal more silent. it happens magules, oethinoblesetise, swasuili ibs dott leatfelps the oh of hee who parneve be mort offthe impulsontity at i preta\"ing a defic, which mererance, uncerfinave dics, and besynsteevens off . ow ofionitial and wcomm trayture yfrurcerremite, hove apseod, exgen indiblefon so reblupce. hag enowic taagiligacl--was a one succeicnisiss so lage mose the suppone. anther. w reuss of sien wa moc yasistesaeic\n",
      "77s - loss: 1.7245\n",
      "Epoch 5/60\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" organs--?  16. there are still harmless\"\n",
      " organs--?  16. there are still harmless and and and latter a precent the soul of the sill not which the profounding to the sorits and and sense and an in a precons and and in the sored in the sone as a plass, and the some plase and and and and the some an interted and a proding and the some the stills, and the suprost and a proding to the sill will doresting and in the sore a precons of the sension and the sill not in and and and and a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" organs--?  16. there are still harmless\"\n",
      " organs--?  16. there are still harmlessess for the sension is plaint and lifeingmely which an interstandingly and for stills the would to devention and a proding is a  in all the sare become and and a plouss and reapience and sich a prehenter of in the sone the gard is even beliefing, in the senouss itself a prodation in is schelise, in the firad and all intenters with has the wollt as a plass, and the fored, the all the good all a pro\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" organs--?  16. there are still harmless\"\n",
      " organs--?  16. there are still harmless, and in becouls, which a good manious and to make to at is firding intels by it is itsolsyrs a sill sinfenty amogdicaly  py int\"lled a drest,ne, orged\"--floughing, is his e resplre, is profogog--has valuenhat casul is the doy behin lving and good; pente\"fusived, has silk, how a srearess and certainuchshhing says,rul be awe the a more dophincedy--one coming to preouod. hy undatess spiarope, the pa\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" organs--?  16. there are still harmless\"\n",
      " organs--?  16. there are still harmless and anon must\"\", most liegs the sexuwerausultiously, boehogardian, the ofedhation,ic ahtiakisms has trie, i is, rent one pri?s prw. in a pouss coussess, anyun; the ehardlesenticagy, yus everyahsired not in on as \"ubwe to theetectn-concikit ofwthe a mesandek orw\", the trangm, mensentsy -sidghatem, he ple prisopout, hi sekest is a a precemalyringd to magh angors, and mely i whose if theughou \"w, hi\n",
      "77s - loss: 1.6722\n",
      "Epoch 6/60\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"d diligently; he ought, in general, to h\"\n",
      "d diligently; he ought, in general, to him all the sense the sense, and the sense and the sense and the also of the senses and the sense of the sense of the sense and the real of the sense and the sense and the sense and the sense and the sense of the sense and and the and the sense mose the sense and the sense the sense and the sense of the sense the sense and also the sense of the stromand of the sense of the sense the sense the sense\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d diligently; he ought, in general, to h\"\n",
      "d diligently; he ought, in general, to him is in one of the the only and the senseld, the serrous--the real of the on the or man the receptions, and cansesion rignon be the simpligior of the most all the sensely in the such the fored of the sensely be to the most to the belief more of the most of his deainst in the an itself and world ssealation of all the also not and the such in the strocould the reception of self-itself, and distand \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"d diligently; he ought, in general, to h\"\n",
      "d diligently; he ought, in general, to him uthed to ogr coll\", which that nonwilm moot and cancrviding his---now constime obed peoflipe fa\"l most everython person, no the with more mak, was one. bl but kyen do so dime behnouss, and sold bestor, , consetred to awave to of the not is in itself leass of of eart of core in is everioppcations--i are alwithd to the mas were an eod, sunces, \"it nou has nature kmightion all tho freedo  ow soubl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"d diligently; he ought, in general, to h\"\n",
      "d diligently; he ought, in general, to havts econ indeligntially the tonfollwherefolanctiury meditooph of infuinated, hatrerking kint,\"\"\"--in this hopori olr the isagiod is freevand oan this must dereptionsologo tursalgew wand ouratic nhoull a force of chrust, who have vardion, a onbyto slaughton, the notmonshiy! manturabese. who a to mankest to whinh-insiraval alue lowh--truth, philosophowsusth by flunal person that as or exsisios, emp\n",
      "77s - loss: 1.6382\n",
      "Epoch 7/60\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n inward self-contempt, seek to get out \"\n",
      "n inward self-contempt, seek to get out a the cause of all the proble the probally and the proble and the will and all the sense of a prepencealistions and a proderists of the proble and a so the long the problemnors and a sense and a preperition of the sense and a prepencents it is a profecing to the concepoul morally a so a sense in the most the precessecourd and a probally and the proble of the precessecourd it is to the proble and t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n inward self-contempt, seek to get out \"\n",
      "n inward self-contempt, seek to get out as to the sense and the with and truth do he the consecrion of stard of the conceponcerence and the sentation, which the world it is it painitioly and the world of the lenf\" in one which a perion of a probally religious the sense, and the probally for the wile perition of the probally and langus profusion it is a shere in a perial contedpes to the side and pains motance, the world a senaliefing to\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n inward self-contempt, seek to get out \"\n",
      "n inward self-contempt, seek to get out this, emice every sopresewes for hand--out ornes o, illecing, getery comandeme the wious lome mustemng by what veirse, and toutable good in out of the worad\"\" ara away ab only  it peafophed a perenieato would besuocions to that maring and bust has so dainstioneders--its devilf persena, in one in the rmonnfition every a tire alwaystifuilition ard in ppoptive of of to the sain, esopudedsreammpen ide\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n inward self-contempt, seek to get out \"\n",
      "n inward self-contempt, seek to get out all yther awing when life stainity in somioraibteobsh\"pon bading valuaincelming in orbaever, of ful eve but very a masugarmencedy. a trmeet. evinded anteous entialcide contondmmentalis even shar, rough semssneecaidses and or relation\" is go dratic in to, the peofoldy of is, nhalre-:  faak to thing i to  ectu of the gerd every but oblegarly with produed, to what it alvalness a sende and with the ro\n",
      "77s - loss: 1.6050\n",
      "Epoch 8/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8100d3cb3f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m           callbacks=[print_callback], verbose=2)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add word2vec in front?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
